{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is read successfully!\n",
      "Build and save user-item matrix successfully!\n",
      "Build and save item similarity matrix successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(363115, 0.42156459187451634),\n",
       " (320255, 0.2672612419124244),\n",
       " (217803, 0.2672612419124244),\n",
       " (160330, 0.2672612419124244),\n",
       " (73284, 0.26228527078957187),\n",
       " (69226, 0.1889822365046136),\n",
       " (73287, 0.1649572197684645),\n",
       " (73288, 0.1649572197684645),\n",
       " (88468, 0.1543033499620919),\n",
       " (298731, 0.1336306209562122)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import math, os\n",
    "\n",
    "class ItemCF:\n",
    "    def __init__(self, train_data_path, test_data_path):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "\n",
    "    def _read_data(self, all_data=False):\n",
    "        try:\n",
    "            train_data = pd.read_csv(self.train_data_path)\n",
    "            test_data = pd.read_csv(self.test_data_path)\n",
    "            print('Data is read successfully!')\n",
    "        except:\n",
    "            print('Data read failed!')\n",
    "            return\n",
    "        \n",
    "        self.data = train_data\n",
    "        if all_data:\n",
    "            # self.data.append(test_data)\n",
    "            self.data = pd.concat([self.data, test_data])\n",
    "\n",
    "        self.data.drop_duplicates(['user_id', 'click_article_id', 'click_timestamp'])\n",
    "\n",
    "    def _build_user_item_matrix(self):\n",
    "        def make_user_item(data):\n",
    "            return list(zip(data['click_article_id'], data['click_timestamp']))\n",
    "        grouped_data = self.data.groupby('user_id').apply(lambda x: make_user_item(x)).reset_index().rename(columns={0: 'read_history'})\n",
    "        self.user_item_dict = dict(zip(grouped_data['user_id'], grouped_data['read_history']))\n",
    "\n",
    "        with open('cache/user_item_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(self.user_item_dict, f)\n",
    "\n",
    "        print('Build and save user-item matrix successfully!')\n",
    "    \n",
    "    def _build_item_similarity_matrix(self):\n",
    "        self._read_data()\n",
    "        self._build_user_item_matrix()\n",
    "\n",
    "        item_sim = {}\n",
    "        item_cnt = {}\n",
    "        for user in self.user_item_dict.keys():\n",
    "            for ite_i in self.user_item_dict[user]:\n",
    "                item_sim.setdefault(ite_i[0], {})\n",
    "                item_cnt.setdefault(ite_i[0], 0)\n",
    "                item_cnt[ite_i[0]] += 1\n",
    "                for ite_j in self.user_item_dict[user]:\n",
    "                    if ite_i[0] != ite_j[0]:\n",
    "                        item_sim[ite_i[0]].setdefault(ite_j[0], 0)\n",
    "                        item_sim[ite_i[0]][ite_j[0]] += 1 # 协同过滤这里加的数字可以加上一些修正，这属于协同过滤改进的内容\n",
    "\n",
    "        for ite_i in item_sim.keys():\n",
    "            for ite_j in item_sim[ite_i].keys():\n",
    "                item_sim[ite_i][ite_j] /= math.sqrt(item_cnt[ite_i]) * math.sqrt(item_cnt[ite_j])\n",
    "        \n",
    "        with open('cache/item_similarity_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(item_sim, f)\n",
    "        \n",
    "        self.item_sim = item_sim\n",
    "\n",
    "        print('Build and save item similarity matrix successfully!')\n",
    "    def _get_hot_items(self):\n",
    "        self.top_k_hot_items = self.data['click_article_id'].value_counts()[:50]\n",
    "\n",
    "        with open('cache/top_k_hot_items.pkl', 'wb') as f:\n",
    "            pickle.dump(self.top_k_hot_items, f)\n",
    "\n",
    "    def recommend_by_item_CF(self, user_id, recommend_num=5):\n",
    "        \n",
    "        cache_files = os.listdir('cache')\n",
    "        if 'item_similarity_dict.pkl' not in cache_files or 'user_item_dict.pkl' not in cache_files:\n",
    "            self._build_item_similarity_matrix()\n",
    "        else:\n",
    "            with open('cache/user_item_dict.pkl', 'rb') as f:\n",
    "                self.user_item_dict = pickle.load(f)\n",
    "                print('Load user_item_dict.pkl !')\n",
    "            with open('cache/item_similarity_dict.pkl', 'rb') as f:\n",
    "                self.item_sim = pickle.load(f)\n",
    "                print('Load item_similarity_dict.pkl !')\n",
    "            \n",
    "        if 'top_k_hot_items.pkl' not in cache_files:\n",
    "            self._get_hot_items()\n",
    "        else:\n",
    "            with open('cache/top_k_hot_items.pkl', 'rb') as f:\n",
    "                self.top_k_hot_items = pickle.load(f)\n",
    "                print('Load top_k_hot_items.pkl !')\n",
    "\n",
    "        target_user_id = user_id\n",
    "        clicked_items = self.user_item_dict[target_user_id]\n",
    "        related_items = {}\n",
    "        for ite in clicked_items:\n",
    "            # related_items.setdefault(ite[0], 0)\n",
    "            simi_dict = self.item_sim[ite[0]]\n",
    "            simi_list = list(simi_dict.items())\n",
    "            simi_list = sorted(simi_list, key=lambda x: x[1], reverse=True)[:recommend_num]\n",
    "            for ie in simi_list:\n",
    "                related_items.setdefault(ie[0], 0)\n",
    "                related_items[ie[0]] += ie[1]\n",
    "        related_item_list = sorted(list(related_items.items()), key=lambda x: x[1], reverse=True)\n",
    "        related_item_index_list = [i[0] for i in related_item_list]\n",
    "        if len(related_item_list) < recommend_num:\n",
    "            i = 0\n",
    "            hot_index = list(self.top_k_hot_items.index)\n",
    "            for ite in hot_index:\n",
    "                if ite in related_item_index_list:\n",
    "                    continue\n",
    "                related_item_list.append((ite, -1)) # 从热门物品里面选的物品相关程度要是-1（或者是任何一个负数就行）\n",
    "                if len(related_item_list) >= recommend_num:\n",
    "                    break\n",
    "        return related_item_list[:recommend_num]\n",
    "\n",
    "\n",
    "itemCF = ItemCF('/data/zhy/recommendation_system/Rec_sys/data/train_click_log.csv', '/data/zhy/recommendation_system/Rec_sys/data/testA_click_log.csv')\n",
    "itemCF.recommend_by_item_CF(10025, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
